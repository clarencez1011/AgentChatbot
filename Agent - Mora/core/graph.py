import asyncio
from typing import TypedDict, Annotated, List, Literal
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI  # ğŸ‘ˆ ç¡®ä¿å¯¼å…¥è¿™ä¸ª

from config.settings import Config
from core.prompts import Prompts
from services.llm import llm_service
from tools.rag_tool import lookup_internal_knowledge
from tools.search_tool import search_internet

# 1. å®šä¹‰ State
class AgentState(TypedDict):
    messages: Annotated[List, add_messages]
    original_question: str

# ============================================================
# 2. ğŸ”¥ ä¿®å¤ç‚¹ï¼šå…ˆå®šä¹‰ tools åˆ—è¡¨ï¼Œå†ç»‘å®šç»™ LLM
# ============================================================
tools = [lookup_internal_knowledge, search_internet]

# 3. åˆå§‹åŒ– LLM å¹¶ç»‘å®šå·¥å…·
llm = ChatOpenAI(
    model=Config.LLM_MODEL,
    api_key=Config.ALI_KEY,
    base_url=Config.LLM_BASE_URL,
    temperature=0
)

# ç»‘å®šå·¥å…· (ç°åœ¨ python çŸ¥é“ tools æ˜¯ä»€ä¹ˆäº†)
llm_with_tools = llm.bind_tools(tools)

# ============================================================
# 4. å®šä¹‰èŠ‚ç‚¹ (Async)
# ============================================================

async def node_rewrite(state: AgentState):
    """é¢„å¤„ç†ï¼šä¼˜åŒ–ç”¨æˆ·é—®é¢˜"""
    messages = state["messages"]
    last_msg = messages[-1]
    raw_q = last_msg.content
    
    print(f"   [Rewriter] åŸå§‹é—®é¢˜: {raw_q}")
    
    # å¼‚æ­¥è°ƒç”¨é‡å†™
    new_q = await llm_service.rewrite_query(raw_q, Prompts.SYSTEM_REWRITE)
 
    
    # æ›´æ–°æ¶ˆæ¯å†…å®¹
    last_msg.content = new_q
    return {"messages": [last_msg], "original_question": raw_q}

async def node_agent(state: AgentState):
    """Agent å¤§è„‘"""
    messages = state["messages"]
    
    # æ³¨å…¥ System Prompt
    if not isinstance(messages[0], SystemMessage):
        messages = [SystemMessage(content=Prompts.SYSTEM_AGENT)] + messages
        
    # å¼‚æ­¥è°ƒç”¨ LLM
    response = await llm_with_tools.ainvoke(messages)
    return {"messages": [response]}

def should_continue(state: AgentState) -> Literal["tools", "__end__"]:
    """è·¯ç”±é€»è¾‘ï¼šå†³å®šæ˜¯è°ƒå·¥å…·è¿˜æ˜¯ç»“æŸ"""
    messages = state["messages"]
    last_msg = messages[-1]
    
    if last_msg.tool_calls:
        return "tools"
    return "__end__"

# ============================================================
# 5. æ„å»ºå›¾
# ============================================================

def build_agent_graph():
    workflow = StateGraph(AgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("rewrite", node_rewrite)
    workflow.add_node("agent", node_agent)
    workflow.add_node("tools", ToolNode(tools)) # ä½¿ç”¨ LangGraph è‡ªå¸¦çš„ ToolNode
    
    # è®¾ç½®è¿çº¿
    workflow.set_entry_point("rewrite")
    
    workflow.add_edge("rewrite", "agent")
    
    workflow.add_conditional_edges(
        "agent",
        should_continue,
    )
    
    workflow.add_edge("tools", "agent") # å½¢æˆé—­ç¯ï¼šå·¥å…·ç”¨å®Œå› Agent
    
    return workflow.compile()